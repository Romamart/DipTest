{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from math import isnan\n",
    "import json\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_Data(path_dir):\n",
    "    list_text = os.listdir(path=path_dir)\n",
    "    text_array = ''\n",
    "    for text in list_text:\n",
    "        with open(path_dir + text, 'r') as f:\n",
    "            text_array+= f.readline() + '\\n'\n",
    "    text_array = text_array.replace('\\ufeff', '')\n",
    "    list_of_files = text_array.split('\\n')\n",
    "    for i in range(len(list_of_files)):\n",
    "        list_of_files[i] = list_of_files[i].split('\\t')\n",
    "    text_tmp = []\n",
    "    for i in range(len(list_of_files)):\n",
    "        if list_of_files[i] != ['']:\n",
    "            text_tmp.append(list_of_files[i])\n",
    "    return text_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParseData(data):\n",
    "    list_of_sites, body_array, values = [],[],[];\n",
    "    for i in range(len(data)):\n",
    "        body_array.append([])\n",
    "        for j in range(len(data[i])):\n",
    "            if j == 0:\n",
    "                list_of_sites.append(data[i][j])\n",
    "            elif j == len(data[i])-1:\n",
    "                values.append([int(data[i][j])])\n",
    "            else:\n",
    "                if j != 4:\n",
    "                    if data[i][j] == 'null':\n",
    "                        body_array[i].append(0)\n",
    "                    elif data[i][j] == 'true':\n",
    "                        body_array[i].append(1)\n",
    "                    elif data[i][j] == 'false':\n",
    "                        if j == 2:\n",
    "                            body_array[i].append(0)\n",
    "                        else:\n",
    "                            body_array[i].append(-1)\n",
    "                    else:\n",
    "        #                 print(text_array[i][j])\n",
    "                        body_array[i].append(float(data[i][j]))\n",
    "    return np.concatenate((np.array(body_array), np.array(values)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = ParseData(Load_Data('Data/'))\n",
    "data_test = ParseData(Load_Data('New_test/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, random_split\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhishingRegressor(nn.Module):\n",
    "    def __init__(self, name=''):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.train = None\n",
    "        self.test = None\n",
    "        self.epoch = None\n",
    "        self.loss = nn.BCELoss()\n",
    "        self.linear1 = nn.Linear(10, 1)\n",
    "#         self.linear2 = nn.Linear(10, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         x = torch.tanh(self.linear1(x))\n",
    "        x = torch.sigmoid(self.linear1(x))\n",
    "        return x\n",
    "    \n",
    "    def Pred(self, data, l):\n",
    "#         loss_new = nn.BCELoss()\n",
    "        train_loader = DataLoader(dataset=data, batch_size=l)\n",
    "        acc_new = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.cuda(), y_batch.cuda()\n",
    "            y_pred = self(X_batch)\n",
    "            bce_new = self.loss(y_pred, y_batch)\n",
    "            acc_new = round(sum([int(y_batch[i] == int(y_pred[i][0]>0.5)) for i in range(y_pred.shape[0])])/l, 3)\n",
    "        return bce_new, acc_new\n",
    "\n",
    "    def Data_to_Tensor(self, data, length=[200,20,10]):\n",
    "        ttv = [[],[],[]]\n",
    "        np.random.shuffle(data)\n",
    "        j = 0\n",
    "        num = 0\n",
    "        classes = [[],[]]\n",
    "        for i in range(data.shape[0]):\n",
    "            classes[int(data[i,-1])].append(data[i])\n",
    "        for j in range(len(classes)):\n",
    "            num = 0\n",
    "            u = 0\n",
    "            for k in range(len(classes[j])):\n",
    "                if num != length[u]/2:\n",
    "                    ttv[u].append(classes[j][k])\n",
    "                    num += 1\n",
    "                else:\n",
    "                    if u < len(length) - 1:\n",
    "                        u += 1\n",
    "                        num = 0\n",
    "                    ttv[u].append(classes[j][k])\n",
    "                    num += 1\n",
    "        for i in range(len(ttv)):\n",
    "            ttv[i] = np.array(ttv[i])\n",
    "            np.random.shuffle(ttv[i])\n",
    "        out = []\n",
    "        for i in range(len(ttv)):\n",
    "            out.append(TensorDataset(torch.tensor(ttv[i][:,:-1], dtype=torch.float), torch.tensor(ttv[i][:,-1], dtype=torch.float).view(-1,1)))\n",
    "        return out\n",
    "    def train_model(self, data, length=[200,20,10], f = None):\n",
    "        optimizer = Adam(self.parameters(), lr=1e-3)\n",
    "        epochs, bce_train, bce_val= [], [], []\n",
    "#         loss = nn.BCELoss()\n",
    "        ltrain, ltest, lval = length\n",
    "        Data_train, Data_test, Data_val = self.Data_to_Tensor(data)\n",
    "        train_loader = DataLoader(dataset=Data_train, batch_size=20)\n",
    "        test_loader = DataLoader(dataset=Data_train, batch_size=ltest)\n",
    "        train_loader_show = DataLoader(dataset=Data_train, batch_size=ltrain+ltest+lval) \n",
    "        epoch = 0\n",
    "        max_epoch = 5000\n",
    "        while True:\n",
    "            epochs.append(epoch)\n",
    "            for X_batch, y_batch in train_loader: \n",
    "                X_batch, y_batch = X_batch.cuda(), y_batch.cuda()\n",
    "                y_pred = self(X_batch)    \n",
    "                bce = self.loss(y_pred, y_batch)\n",
    "\n",
    "                bce.backward()        \n",
    "\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()       \n",
    "            \n",
    "            bce_train.append(bce)\n",
    "            bce_val.append(self.Pred(Data_val, lval)[0])\n",
    "            epoch += 1\n",
    "            if epoch % 500 == 0:\n",
    "#                 print(bce.detach().numpy().tolist())\n",
    "                print(f'Epoch = {epoch}, loss = {round(bce.cpu().detach().numpy().tolist(), 5)}, acc_train = {self.Pred(Data_train,ltrain)[1]}, acc_val = {self.Pred(Data_val,lval)[1]}, acc_test = {self.Pred(Data_test,ltest)[1]}')\n",
    "            if self.Pred(Data_train,ltrain)[1]>=0.96:\n",
    "#                 print(self.Pred(Data_test, ltest))\n",
    "                if f:\n",
    "                    f.set_title(f'Model №{self.name}')\n",
    "                    f.plot(epochs,bce_train, color='black')\n",
    "                    f.plot(epochs,bce_val)\n",
    "                break\n",
    "            if epoch == max_epoch:\n",
    "#                 if f:\n",
    "#                     f.set_title(f'Model №{self.name}')\n",
    "#                     f.plot(epochs[:200],bce_train[:200], color='black')\n",
    "#                     f.plot(epochs[:200],bce_val[:200])\n",
    "                break\n",
    "        self.train = train_loader_show\n",
    "        self.test = test_loader\n",
    "        self.epoch = epoch \n",
    "#         return train_loader_show, test_loader\n",
    "    def Save_model_data(self):\n",
    "        for data, val in self.train:\n",
    "            tmp = []\n",
    "            for i in range(data.shape[0]):\n",
    "                dict_tr = {}\n",
    "                dict_tr['input'] = data[i].detach().numpy().tolist()\n",
    "                dict_tr['output'] = val[i].detach().numpy().tolist()\n",
    "                tmp.append(dict_tr)\n",
    "            with open(f'../js_network/Data/train{self.name}.json','w') as f:\n",
    "                json.dump(tmp, f)\n",
    "        for data, val in self.test:\n",
    "            tmp = []\n",
    "            for i in range(data.shape[0]):\n",
    "                dict_tr = {}\n",
    "                dict_tr['input'] = data[i].detach().numpy().tolist()\n",
    "                dict_tr['output'] = val[i].detach().numpy().tolist()\n",
    "                tmp.append(dict_tr)\n",
    "            with open(f'../js_network/Data/test{self.name}.json','w') as f:\n",
    "                json.dump(tmp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [PhishingRegressor(name=str(i+1)).cuda() for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Train model №1:\n",
      "\n",
      "Epoch = 500, loss = 0.24186, acc_train = 0.94, acc_val = 0.8, acc_test = 1.0\n",
      "Epoch = 1000, loss = 0.20363, acc_train = 0.955, acc_val = 0.9, acc_test = 1.0\n",
      "Epoch = 1500, loss = 0.19388, acc_train = 0.955, acc_val = 0.9, acc_test = 1.0\n",
      "\n",
      "Train model №2:\n",
      "\n",
      "Epoch = 500, loss = 0.07905, acc_train = 0.94, acc_val = 1.0, acc_test = 1.0\n",
      "Epoch = 1000, loss = 0.05725, acc_train = 0.945, acc_val = 1.0, acc_test = 1.0\n",
      "Epoch = 1500, loss = 0.05299, acc_train = 0.95, acc_val = 1.0, acc_test = 1.0\n",
      "Epoch = 2000, loss = 0.05259, acc_train = 0.95, acc_val = 1.0, acc_test = 1.0\n",
      "Epoch = 2500, loss = 0.05288, acc_train = 0.95, acc_val = 1.0, acc_test = 1.0\n",
      "Epoch = 3000, loss = 0.05328, acc_train = 0.95, acc_val = 1.0, acc_test = 1.0\n",
      "Epoch = 3500, loss = 0.05367, acc_train = 0.95, acc_val = 1.0, acc_test = 1.0\n",
      "Epoch = 4000, loss = 0.05403, acc_train = 0.955, acc_val = 1.0, acc_test = 1.0\n",
      "Epoch = 4500, loss = 0.05435, acc_train = 0.95, acc_val = 1.0, acc_test = 1.0\n",
      "Epoch = 5000, loss = 0.05463, acc_train = 0.95, acc_val = 1.0, acc_test = 1.0\n",
      "Epoch = 500, loss = 0.08392, acc_train = 0.95, acc_val = 0.9, acc_test = 0.95\n",
      "\n",
      "Train model №3:\n",
      "\n",
      "\n",
      "Train model №4:\n",
      "\n",
      "Epoch = 500, loss = 0.05442, acc_train = 0.95, acc_val = 1.0, acc_test = 0.95\n",
      "Epoch = 1000, loss = 0.03153, acc_train = 0.95, acc_val = 1.0, acc_test = 0.95\n",
      "Epoch = 1500, loss = 0.02548, acc_train = 0.955, acc_val = 1.0, acc_test = 0.95\n",
      "Epoch = 2000, loss = 0.02353, acc_train = 0.955, acc_val = 1.0, acc_test = 0.95\n",
      "Epoch = 2500, loss = 0.02272, acc_train = 0.955, acc_val = 1.0, acc_test = 0.95\n",
      "Epoch = 3000, loss = 0.02232, acc_train = 0.955, acc_val = 1.0, acc_test = 0.95\n",
      "Epoch = 3500, loss = 0.02212, acc_train = 0.955, acc_val = 1.0, acc_test = 0.95\n",
      "Epoch = 4000, loss = 0.02201, acc_train = 0.955, acc_val = 1.0, acc_test = 0.95\n",
      "Epoch = 4500, loss = 0.02196, acc_train = 0.955, acc_val = 1.0, acc_test = 0.95\n",
      "Epoch = 5000, loss = 0.02194, acc_train = 0.955, acc_val = 1.0, acc_test = 0.95\n",
      "Epoch = 500, loss = 0.25715, acc_train = 0.95, acc_val = 1.0, acc_test = 0.95\n",
      "Epoch = 1000, loss = 0.23135, acc_train = 0.955, acc_val = 1.0, acc_test = 0.95\n",
      "Epoch = 1500, loss = 0.21808, acc_train = 0.955, acc_val = 1.0, acc_test = 0.95\n",
      "Epoch = 2000, loss = 0.20938, acc_train = 0.955, acc_val = 1.0, acc_test = 0.95\n",
      "\n",
      "Train model №5:\n",
      "\n",
      "Epoch = 500, loss = 0.10317, acc_train = 0.945, acc_val = 0.9, acc_test = 1.0\n",
      "Epoch = 1000, loss = 0.09579, acc_train = 0.955, acc_val = 0.9, acc_test = 1.0\n",
      "Epoch = 1500, loss = 0.0953, acc_train = 0.955, acc_val = 0.9, acc_test = 0.95\n",
      "Epoch = 2000, loss = 0.09557, acc_train = 0.95, acc_val = 0.8, acc_test = 0.95\n",
      "Epoch = 2500, loss = 0.09639, acc_train = 0.95, acc_val = 0.8, acc_test = 0.95\n",
      "Epoch = 3000, loss = 0.09738, acc_train = 0.95, acc_val = 0.8, acc_test = 0.95\n",
      "Epoch = 3500, loss = 0.09827, acc_train = 0.945, acc_val = 0.8, acc_test = 0.95\n",
      "Epoch = 4000, loss = 0.09894, acc_train = 0.955, acc_val = 0.9, acc_test = 0.95\n",
      "Epoch = 4500, loss = 0.09938, acc_train = 0.955, acc_val = 0.9, acc_test = 0.95\n",
      "Epoch = 5000, loss = 0.09967, acc_train = 0.955, acc_val = 0.9, acc_test = 0.95\n",
      "Epoch = 500, loss = 0.08373, acc_train = 0.94, acc_val = 1.0, acc_test = 0.95\n",
      "Epoch = 1000, loss = 0.05383, acc_train = 0.95, acc_val = 1.0, acc_test = 0.95\n",
      "Epoch = 1500, loss = 0.04897, acc_train = 0.95, acc_val = 1.0, acc_test = 0.95\n",
      "Epoch = 2000, loss = 0.04728, acc_train = 0.95, acc_val = 1.0, acc_test = 0.95\n",
      "Epoch = 2500, loss = 0.04624, acc_train = 0.95, acc_val = 1.0, acc_test = 0.95\n",
      "Epoch = 3000, loss = 0.04539, acc_train = 0.95, acc_val = 1.0, acc_test = 0.95\n",
      "Epoch = 3500, loss = 0.04461, acc_train = 0.955, acc_val = 1.0, acc_test = 0.95\n",
      "Epoch = 4000, loss = 0.04388, acc_train = 0.955, acc_val = 1.0, acc_test = 0.95\n",
      "Epoch = 4500, loss = 0.04319, acc_train = 0.955, acc_val = 1.0, acc_test = 0.95\n",
      "Epoch = 5000, loss = 0.04254, acc_train = 0.955, acc_val = 1.0, acc_test = 0.95\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1856, 880, 188, 2386, 225]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "epochs = []\n",
    "f_mod, axes = plt.subplots(1,len(models), num='NN models')\n",
    "i = 0\n",
    "for model in models:\n",
    "    print(f'Train model №{model.name}:\\n')\n",
    "    model.train_model(data_all, f=axes[i])\n",
    "    if model.epoch == 5000:\n",
    "        while model.epoch == 5000:\n",
    "            model = PhishingRegressor(name=model.name).cuda()\n",
    "            model.train_model(data_all, f=axes[i])\n",
    "    epochs.append(model.epoch)\n",
    "#     model.Save_model_data()\n",
    "    print()\n",
    "    i+=1\n",
    "# with open(f'../js_network/Data/epochs.json','w') as f:\n",
    "#     json.dump(epochs, f)\n",
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "def get_color_array(array, f=lambda x: x):\n",
    "    return ['red' if f(array[i]) > 0.5 else 'blue' for i in range(len(array))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to2D = TSNE(learning_rate=1)\n",
    "transform = model_to2D.fit_transform(data_all[:,:-1])\n",
    "x = transform[:,0]\n",
    "y = transform[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = data_all.T[-1]\n",
    "y_val_color = get_color_array(y_val, lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_for_model = TensorDataset(torch.tensor(data_all[:,:-1], dtype=torch.float), torch.tensor(data_all[:,-1], dtype=torch.float).view(-1,1))\n",
    "data_load = DataLoader(dataset=data_for_model, batch_size=data_all.shape[0])\n",
    "f_lr, ax = plt.subplots(5,1, num='Res models')\n",
    "for a,b in data_load:\n",
    "    a,b = a.cuda(),b.cuda()\n",
    "    tmp = []\n",
    "    i = 0\n",
    "    my_f = lambda x: 0.5\n",
    "    y_plot = np.array([my_f(x[i]) for i in range(x.shape[0])])\n",
    "#     print(y_plot)\n",
    "    for model in models:\n",
    "        tmp.append(model(a)[:,0].cpu().detach().numpy())\n",
    "        ax[i].scatter(x,model(a)[:,0].cpu().detach().numpy(), c=y_val_color)\n",
    "        ax[i].plot(x,y_plot)\n",
    "        i+=1\n",
    "    tmp = np.array(tmp).T\n",
    "    t = b.cpu().detach().numpy()\n",
    "# Data_con = np.concatenate((tmp.T, t), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_models(data, models):\n",
    "    data_for_model = TensorDataset(torch.tensor(data[:,:-1], dtype=torch.float), torch.tensor(data[:,-1], dtype=torch.float).view(-1,1))\n",
    "    data_load = DataLoader(dataset=data_for_model, batch_size=data.shape[0])\n",
    "    t = []\n",
    "    acc_arr = []\n",
    "    for a,b in data_load:\n",
    "        a,b = a.cuda(),b.cuda()\n",
    "        t = b.cpu().detach().numpy()\n",
    "        tmp = []\n",
    "        j = 0\n",
    "        for model in models:\n",
    "            tmp.append(model(a)[:,0].cpu().detach().numpy())\n",
    "            acc_arr.append(sum([int(t[i] == int(tmp[j].T[i] >= 0.5)) for i in range(t.shape[0])])/t.shape[0])\n",
    "            j += 1\n",
    "    tmp = sum(np.array(tmp)).T/len(models)\n",
    "    acc = sum([int(t[i] == int(tmp[i] >= 0.5)) for i in range(t.shape[0])])/t.shape[0]\n",
    "    return [int(tmp[i] >= 0.5) for i in range(t.shape[0])], [acc, acc_arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9521739130434783,\n",
       " [0.9608695652173913,\n",
       "  0.9565217391304348,\n",
       "  0.9478260869565217,\n",
       "  0.9565217391304348,\n",
       "  0.9521739130434783]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_all, acc_all = res_models(data_all, models)\n",
    "acc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8, [0.9, 0.85, 0.8, 0.8, 0.85]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test, acc_test = res_models(data_test, models)\n",
    "acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_acc = int(np.array(acc_test[1]).argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../js_network/Data/max_acc.json', 'w') as f:\n",
    "#     json.dump(max_acc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_all_color = get_color_array(res_all)\n",
    "val_all_color = get_color_array(data_all[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "f_train, ax1 = plt.subplots(1,2, sharey=True)\n",
    "ax1[0].scatter(x, y, c=val_all_color)\n",
    "ax1[0].set_title('без обработки')\n",
    "ax1[1].scatter(x, y, c=res_all_color)\n",
    "ax1[1].set_title('результат модели')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = model_to2D.fit_transform(data_test)\n",
    "x_2 = transform_test[:, 0]\n",
    "y_2 = transform_test[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test_color = get_color_array(res_test)\n",
    "val_test_color = get_color_array(data_test[:,-1])\n",
    "len(res_test_color), len(val_test_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test, ax2 = plt.subplots(1,2, sharey=True)\n",
    "ax2[0].scatter(x_2, y_2, c=val_test_color)\n",
    "ax2[0].set_title('Тестовое множесто')\n",
    "ax2[1].scatter(x_2, y_2, c=res_test_color)\n",
    "ax2[1].set_title('Результат модели')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
